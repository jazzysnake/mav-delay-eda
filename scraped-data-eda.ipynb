{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63fa9913-03f1-4982-822c-027fe327990d",
   "metadata": {},
   "source": [
    "# Hungarian train delay cause EDA\n",
    "\n",
    "This data was scraped by us, from the 2022.10.05 until the time of posting. The need to scrape\n",
    "data arose from the fact, that the data we obtained from reddit did not include the causes of delays.\n",
    "However, as this data is much smaller in size (~4.2M records, only about 1.5 months worth), some conclusions can not\n",
    "be drawn with high confidence. Where we feel like this is the case, a notice wil be present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f699df74-f82a-46fe-9469-64dff749e156",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import dask.dataframe as dd\n",
    "import dask.array as da\n",
    "import dask.bag as db\n",
    "\n",
    "import re\n",
    "\n",
    "#import bamboolib\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329b6829-4d1d-4646-9969-3df3fa0b9669",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('credentials.txt','r') as f:\n",
    "    user = f.readline().strip()\n",
    "    pw = f.readline().strip()\n",
    "connection_url = f'postgresql://{user}:{pw}@vm.niif.cloud.bme.hu:17397/mav'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc4ee6b-bd82-4695-a0b7-83cf4a0ad6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_df = dd.read_sql_table('train_data', connection_url, index_col='id')\n",
    "train_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13916190-42b5-46d7-830c-a337aedf6a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "contains_number_regex = re.compile('\\d')\n",
    "def contains_number(string):\n",
    "    return contains_number_regex.search(string) is not None\n",
    "def isin_list_of_strings(element: str, list_of_strings: list[str]) -> bool:\n",
    "    return np.any([element in item for item in list_of_strings])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba1a347-5ddb-412d-9c5a-41e9b6365fbb",
   "metadata": {},
   "source": [
    "## Tidying data\n",
    "\n",
    "The causes of the delays can not be queried alone, they are included in the \n",
    "detailed information about each train, which is server side rendered and is not\n",
    "placed into a separate field. For this reason the data is messy and must be filtered,\n",
    "as there would be thousands of invalid delay causes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116952fc-7c45-47c5-b01b-f69c2c628a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "delay_causes = train_data_df.delay_cause.unique().compute()\n",
    "delay_causes = np.where(delay_causes.str.contains(';'),delay_causes.str.split(';'),delay_causes)\n",
    "delay_causes = pd.Series([cause[-1] if type(cause) is list else cause for cause in delay_causes])\n",
    "delay_causes = delay_causes[(delay_causes.str.contains('késés')&~delay_causes.apply(contains_number))].unique()\n",
    "delay_causes = pd.Series(delay_causes).str.strip('. \\n\\t')\n",
    "delay_causes.to_csv('data/filtered_causes.csv')\n",
    "delay_causes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a232652-8291-42d0-96f2-48bd177f7df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "delay_causes = pd.read_csv('data/filtered_causes.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bce4549-f95e-403f-b55c-311bb8db36c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tidy_causes(df, cause_col_name):\n",
    "    df[cause_col_name] = np.where(df[cause_col_name].str.contains(';'),df[cause_col_name].str.split(';'),df[cause_col_name])\n",
    "    df[cause_col_name] = df[cause_col_name].apply(lambda cause: cause[-1] if type(cause) is list else cause)\n",
    "    df[cause_col_name] = df[cause_col_name].str.rstrip('. \\n\\t')\n",
    "    df = df[(df[cause_col_name].str.contains('késés')&~df[cause_col_name].apply(contains_number))]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb036bd-0a64-4827-b940-12db4d9b8f1c",
   "metadata": {},
   "source": [
    "## Top delay causes\n",
    "\n",
    "Finding the most frequently cited delay causes is valuable information for\n",
    "diagnosing the most problematic shortcomings of the current system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5f75e2-7a1d-437e-9fed-ed0adaff94b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "delay_group = train_data_df[['elvira_id','delay_cause']].groupby(['delay_cause','elvira_id']).count().compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40516e13-5929-4562-83bf-45ff897667d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "delay_group = delay_group.reset_index()\n",
    "delay_group = delay_group.groupby('delay_cause').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e1c6fc-3125-42a0-95e2-c40e84c35be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "delay_group_filtered = delay_group.sort_values(by='elvira_id', ascending = False).reset_index()\n",
    "delay_group_filtered = tidy_causes(delay_group_filtered, 'delay_cause') \n",
    "delay_group_filtered = delay_group_filtered.groupby('delay_cause').sum().reset_index()\n",
    "delay_group_filtered = delay_group_filtered.sort_values(by='elvira_id', ascending = False)\n",
    "delay_group_filtered = delay_group_filtered[delay_group_filtered['delay_cause'].apply(lambda x: isin_list_of_strings(x,delay_causes.values))]\n",
    "delay_group_filtered = delay_group_filtered.rename(columns={'elvira_id':'occurrence_count'})\n",
    "delay_group_filtered = delay_group_filtered[~(delay_group_filtered['delay_cause']=='')] \n",
    "delay_group_filtered.to_csv('data/occurrence_delay_causes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8935932-17cf-47d6-9f1c-d0379813fe33",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df = pd.read_csv('data/occurrence_delay_causes.csv', index_col = 0).head(10)\n",
    "print(plot_df)\n",
    "fig = px.bar(plot_df, x = 'delay_cause', y = 'occurrence_count',title='Top 10 delay causes')\n",
    "fig.update_yaxes(title_text='occurrence count (logarithmic)')\n",
    "fig.update_xaxes(title_text='delay cause')\n",
    "fig.update_yaxes(type='log')\n",
    "fig.update_layout(width=800, height=600)\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba76441-c3c9-4f5e-97ec-3698bf71370b",
   "metadata": {},
   "source": [
    "## Most frequent delay cause on each route\n",
    "\n",
    "The most frequently cited delays on each route can reveal a lot about the\n",
    "route's condition or possibly the trains' that operate on them. It can also\n",
    "save lives, because new safety measures can be put in places where there are\n",
    "large delays due to accidents.\n",
    "\n",
    "**The observed duration might not be sufficiently long to use this data as conclusive evidence** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99cbd8f2-cb09-4247-8787-8477a61e5444",
   "metadata": {},
   "outputs": [],
   "source": [
    "delay_per_route = train_data_df[['relation','delay_cause']].groupby(['relation','delay_cause']).count().compute()\n",
    "delay_per_route = delay_per_route.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0398222e-2629-4736-b720-bfdf1f0cc055",
   "metadata": {},
   "outputs": [],
   "source": [
    "def immutable_sort(list_to_sort:list) -> list:\n",
    "    res = list_to_sort.copy()\n",
    "    res.sort()\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0578694e-910f-464b-a8fc-9cc46b78ff77",
   "metadata": {},
   "outputs": [],
   "source": [
    "delay_per_route_filtered = delay_per_route[~np.isin(delay_per_route['delay_cause'],['NaN','nan'])]\n",
    "delay_per_route_filtered = tidy_causes(delay_per_route_filtered, 'delay_cause')\n",
    "delay_per_route = delay_per_route[delay_per_route['delay_cause'].apply(lambda x: isin_list_of_strings(x,delay_causes.values))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153b5561-b9d0-4906-955b-ca6b3a1521d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "delay_per_route_filtered['tmp'] = delay_per_route_filtered['relation'].str.split(' - ')\n",
    "delay_per_route_filtered['tmp'] = delay_per_route_filtered['tmp'].apply(immutable_sort)\n",
    "delay_per_route_filtered['relation'] = delay_per_route_filtered['tmp'].apply(lambda x: f'{x[0]} - {x[1]}')\n",
    "delay_per_route_filtered = delay_per_route_filtered.drop(columns=['tmp'])\n",
    "delay_per_route_filtered = delay_per_route_filtered.groupby(['relation', 'delay_cause']).agg(delay_cause_size=('delay_cause', 'size')).reset_index()\n",
    "cause_copy = delay_per_route_filtered['delay_cause'].copy()\n",
    "delay_per_route_filtered = delay_per_route_filtered.groupby(['relation']).agg(delay_cause_size_idxmax=('delay_cause_size', 'idxmax')).reset_index()\n",
    "delay_per_route_filtered['delay_cause_size_idxmax'] = delay_per_route_filtered['delay_cause_size_idxmax'].apply(lambda x: cause_copy[x])\n",
    "delay_per_route_filtered = delay_per_route_filtered.rename(columns={'delay_cause_size_idxmax':'most_frequent_delay_cause'})\n",
    "delay_per_route_filtered.to_csv('data/delay_cause_route.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efaff99e-2b2f-4ea8-aa19-3d96dde8eb29",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df = pd.read_csv('data/delay_cause_route.csv', index_col = 0)\n",
    "plot_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c601759a-5830-4366-b694-64000a026330",
   "metadata": {},
   "source": [
    "## Delay time for each cause\n",
    "\n",
    "While the most frequent delay causes are useful for diagnosing frequently occurring problems, finding the\n",
    "delays causes that result in the longest average delays and fixing their root causes can help eliminate the\n",
    "delays that are most damaging for customer satisfaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82d7dd3-f004-418f-b05e-190e677e9713",
   "metadata": {},
   "outputs": [],
   "source": [
    "delay_time = train_data_df[['elvira_id','delay_cause','delay']].loc[~(train_data_df['delay_cause'].str.contains('NaN'))&\n",
    "                                                                    ~(train_data_df['delay_cause'].str.contains('nan'))]\n",
    "delay_time = delay_time.groupby(['elvira_id', 'delay_cause']).mean().reset_index()\n",
    "delay_time = delay_time.groupby(['delay_cause']).agg({'delay': { 'mean':np.mean, 'weight':'count'}}).reset_index()\n",
    "delay_time = delay_time.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4bd307-66c1-489f-8ec9-9174caffbe4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "delay_time = tidy_causes(delay_time, 'delay_cause')\n",
    "delay_time.columns = [\"_\".join([str(index) for index in multi_index]) for multi_index in delay_time.columns.ravel()]\n",
    "wm = lambda x: np.average(x, weights=delay_time.loc[x.index, 'delay_weight'])\n",
    "delay_time1 = delay_time.groupby(['delay_cause_']).agg(weight_mean = ('delay_mean',wm)).reset_index()\n",
    "delay_time2 = delay_time.groupby(['delay_cause_']).agg(occurrences = ('delay_weight','sum')).reset_index()\n",
    "delay_time = pd.merge(delay_time1, delay_time2, on='delay_cause_', how='inner')\n",
    "delay_time = delay_time[delay_time['occurrences']>1].rename(columns={'delay_cause_':'delay_cause'}).sort_values(by=['weight_mean'], ascending=[False])\n",
    "delay_time.to_csv('data/mean_delay_times_causes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7aa7095-5300-4c62-b79d-4ebc2a34d9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df = pd.read_csv('data/mean_delay_times_causes.csv', index_col = 0).head(10)\n",
    "print(plot_df)\n",
    "fig = px.bar(plot_df, x='delay_cause', y='weight_mean', title='Mean delay times for causes (Top 10)')\n",
    "fig.update_xaxes(title_text='delay cause')\n",
    "fig.update_yaxes(title_text='mean delay (minutes)')\n",
    "fig.update_layout(width=800, height=600)\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85626c63-8d69-49d2-9d55-a915ddcc78cf",
   "metadata": {},
   "source": [
    "## Top 10 delays and their causes\n",
    "\n",
    "Not immensely helpful, but kind of fun to look at :D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a474b1b3-c05c-41e7-9680-26a4c209fa65",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_10_delays = train_data_df[['elvira_id','delay_cause','delay']].loc[~(train_data_df['delay_cause'].str.contains('NaN'))&\n",
    "                                                                    ~(train_data_df['delay_cause'].str.contains('nan'))]\n",
    "top_10_delays = top_10_delays.groupby(['elvira_id', 'delay_cause']).mean().reset_index()\n",
    "top_10_delays = top_10_delays.sort_values(by=['delay'], ascending=[False]).head(100)\n",
    "top_10_delays = dd.merge(left=top_10_delays,right=train_data_df[['elvira_id','relation']],on=['elvira_id'],how='left')\n",
    "top_10_delays = top_10_delays.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ca6a0e-84c8-4df0-a6c6-fffb4373c4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_10_delays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346a0c76-a9c2-4277-85ea-41ccb92f9850",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_10_delays = top_10_delays.drop_duplicates()\n",
    "top_10_delays = top_10_delays.sort_values(by=['delay'], ascending=[False])\n",
    "top_10_delays = top_10_delays.drop_duplicates(['elvira_id'])\n",
    "top_10_delays = tidy_causes(top_10_delays,'delay_cause')\n",
    "top_10_delays = top_10_delays.drop(columns=['elvira_id'])\n",
    "top_10_delays.to_csv('data/top_delays_w_causes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a646a61-283a-4b7d-b830-c85eefc47250",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df = pd.read_csv('data/top_delays_w_causes.csv', index_col = 0).head(10)\n",
    "plot_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896f0759-aa20-4920-8540-968a638f6b46",
   "metadata": {},
   "source": [
    "## Cumulative delays for each cause\n",
    "\n",
    "Frequently occurring delays might result in small delays in which case they might not be a very significant\n",
    "share of the total time of delays. This metric helps to find the causes responsible for the most cumulative delays.\n",
    "This also shines a bright light upon the ugly truth that the customers and workers of the hungarian railway company\n",
    "probably knew intuitively already. The infrastructure is in dire need of servicing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd282d0-a87b-43ce-b279-98bcd56fbf35",
   "metadata": {},
   "outputs": [],
   "source": [
    "cumulative_delay_time = train_data_df[['elvira_id','delay_cause','delay']].loc[~(train_data_df['delay_cause'].str.contains('NaN'))&\n",
    "                                                                    ~(train_data_df['delay_cause'].str.contains('nan'))]\n",
    "cumulative_delay_time = cumulative_delay_time.groupby(['elvira_id', 'delay_cause']).mean().reset_index()\n",
    "cumulative_delay_time = cumulative_delay_time.groupby(['delay_cause']).sum().reset_index()\n",
    "cumulative_delay_time = cumulative_delay_time.compute()\n",
    "cumulative_delay_time.to_csv('data/cumul_time_cause.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "547ef36b-0205-4070-8b86-a78f14a97a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "cumulative_delay_time = pd.read_csv('data/cumul_time_cause.csv', index_col = 0)\n",
    "cumulative_delay_time_plot = tidy_causes(cumulative_delay_time, 'delay_cause')\n",
    "cumulative_delay_time_plot = cumulative_delay_time_plot.groupby(by=['delay_cause']).sum().reset_index().sort_values(by=['delay'], ascending=[False])\n",
    "cumulative_delay_time_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d436b559-e918-408a-be45-b1e83dad810f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.bar(cumulative_delay_time_plot.head(10), x='delay_cause', y='delay', title = 'Cumulative delays by cause (Top 10)')\n",
    "fig.update_yaxes(type='log')\n",
    "fig.update_xaxes(title_text='delay cause')\n",
    "fig.update_yaxes(title_text='cumulative delay (minutes, logarithmic) ')\n",
    "fig.update_layout(width=800, height=600)\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436e5e61-a87e-45de-bdc6-2b450e801383",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_delays = cumulative_delay_time_plot['delay'].sum()\n",
    "cumulative_delay_time_plot_pie = cumulative_delay_time_plot.copy()\n",
    "cumulative_delay_time_plot_pie['percentage'] = (cumulative_delay_time_plot['delay']/all_delays)*100\n",
    "cumulative_delay_time_plot_pie_other = cumulative_delay_time_plot_pie[cumulative_delay_time_plot_pie['percentage']<5].sum()\n",
    "cumulative_delay_time_plot_pie_other = pd.DataFrame(cumulative_delay_time_plot_pie_other).T\n",
    "cumulative_delay_time_plot_pie_other['delay_cause'] = 'Egyéb'\n",
    "cumulative_delay_time_plot_pie = cumulative_delay_time_plot_pie[cumulative_delay_time_plot_pie['percentage'] > 5]\n",
    "cumulative_delay_time_plot_pie = pd.concat([cumulative_delay_time_plot_pie,cumulative_delay_time_plot_pie_other])\n",
    "cumulative_delay_time_plot_pie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4976ad98-f015-404f-8b90-dc546a8b990e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.pie(cumulative_delay_time_plot_pie, values='delay', names='delay_cause', title='Share of total delays for each cause')\n",
    "fig.update_layout(width=800, height=600)\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a285bb94-ff83-49a5-a2b1-1017d57e4523",
   "metadata": {},
   "source": [
    "## Training dataset\n",
    "This dataset will be used to train an ML model to predict the delay causes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832ec187-1879-4c8c-93e3-c2b40856478f",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = train_data_df.loc[train_data_df['delay']<500]\n",
    "training_data = training_data.groupby('elvira_id').agg({'timestamp':'min',\n",
    "                                                        'relation':'first',\n",
    "                                                        'train_number':'first',\n",
    "                                                        'delay':'mean',\n",
    "                                                        'delay_cause':'list'}).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc45dd43-7272-4c48-b10f-63012d29fa21",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_filtered = training_data.reset_index()\n",
    "training_data_filtered = training_data_filtered.drop(columns=['elvira_id'])\n",
    "cause_column = training_data_filtered['delay_cause'].apply(np.unique)\n",
    "cause_column = cause_column.apply(lambda x: list(filter(lambda y: y != 'NaN' and y != 'nan', x)))\n",
    "cause_column = cause_column.apply(lambda x: np.nan if x == [] else x)\n",
    "cause_column = cause_column.apply(lambda x: x[-1] if type(x) is list else x)\n",
    "cause_column = cause_column.astype(str)\n",
    "cause_column = cause_column.apply(lambda x: x.split(';') if x != np.nan and ';' in x else x)\n",
    "cause_column = cause_column.apply(lambda cause: cause[-1] if type(cause) is list else cause)\n",
    "cause_column = cause_column.str.rstrip('. \\r\\n\\t')\n",
    "training_data_filtered['delay_cause'] = cause_column\n",
    "training_data_filtered = training_data_filtered[training_data_filtered['delay_cause'].apply(lambda x: True if x == 'nan' else isin_list_of_strings(x,delay_causes.values))]\n",
    "\n",
    "vals = training_data_filtered.delay_cause.value_counts()\n",
    "idk = len(training_data_filtered.delay_cause)\n",
    "frequencies = vals/idk\n",
    "causes_to_keep = np.array(vals[frequencies > 0.001].index)\n",
    "training_data_filtered = training_data_filtered[training_data_filtered['delay_cause'].apply(lambda x: True if x == 'nan' else isin_list_of_strings(x,causes_to_keep))]\n",
    "training_data_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d711b07-0414-4f51-b656-c93dec13c8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_filtered.to_csv('data/training_data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
