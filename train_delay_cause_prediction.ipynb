{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Delay cause prediction\n",
    "\n",
    "Using the data collected since 2022.10.05 we tried to build a model that predicts the cause of the delays based on information that is available prior to the journey.\n",
    "As \"no delay\" is also a possible prediction of the model, we are able to predict whether the train will be late or not. Since MAV only gives delay causes for delays that are\n",
    "over 5-6 minutes, the no delay classification given by the model should be interpreted similarly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p93r1GVeTnag"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "random_state = 42\n",
    "np.random.seed(random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading the preprepared training data from disk. The data was created by running the query in the \"scraped-data-eda\" notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "8vyNy3oSURq8",
    "outputId": "5a025bed-0342-499c-b7f8-61c476efd96b"
   },
   "outputs": [],
   "source": [
    "# read the dataset\n",
    "df = pd.read_csv('data/training_data.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing the data\n",
    "The model uses the time of day (hour only), the route name, and the train numbers as input. The target variable is the delay cause.\n",
    "Altough the train number is categorical data without order, we decided to not use one-hot encoding, as sparsly encoding the huge number of trains drastically enlarged our dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "zA9gOZMgTI5A",
    "outputId": "c0ae2698-1b00-4de9-859e-4a4bc8111d3d"
   },
   "outputs": [],
   "source": [
    "# drop the delay column\n",
    "df = df.drop(columns=['delay'])\n",
    "\n",
    "# transform timestamp to hour\n",
    "df['timestamp'] = df['timestamp'].apply(lambda x: datetime.fromtimestamp(x / 1000).hour)\n",
    "\n",
    "# encode the non-numberic values\n",
    "df['relation'] = df['relation'].apply(hash)\n",
    "df['train_number'] = df['train_number'].apply(hash)\n",
    "df['delay_cause'] = np.where(df['delay_cause'].isna(), 'no delay', df['delay_cause'])\n",
    "#df = df[~df['delay_cause'].isna()]\n",
    "categories = pd.Categorical(df['delay_cause'])\n",
    "df['delay_cause'] = categories.codes\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the collection of data started in 2022.10.05, the causes that are relatively infrequent did not appear enough times in the training dataset for the model to sufficiently learn the patterns necessary for predicting the causes accurately. To compensate for this, we oversampled the less frequent causes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lmSfb19NU0ds"
   },
   "outputs": [],
   "source": [
    "# split the dataset into 80% training and 10% test 10% validation set\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(df.drop(columns=['delay_cause']), df.delay_cause, test_size=0.2, random_state=random_state)\n",
    "#X_test, X_valid, Y_test, Y_valid = train_test_split(X_test, Y_test, test_size=0.5, random_state=random_state)\n",
    "\n",
    "# normalize the values\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "#X_valid = scaler.transform(X_valid)\n",
    "# the dataset is imbalanced, therefore we oversample to try to correct this\n",
    "values, counts = np.unique(Y_train, return_counts=True)\n",
    "print(pd.DataFrame({'values':values, 'counts':counts}))\n",
    "ros = RandomOverSampler()\n",
    "X_train, Y_train = ros.fit_resample(X_train, Y_train)\n",
    "values, counts = np.unique(Y_train, return_counts=True)\n",
    "print(pd.DataFrame({'values':values, 'counts':counts}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model building\n",
    "We tried many methods (KNN, Neural Network, Naive Bayes, SVM), but RandomForest gave the best results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jiGLsEthnINf",
    "outputId": "790932f7-22b8-43c4-f212-30647c74f0e9"
   },
   "outputs": [],
   "source": [
    "# create a random forest classifier model\n",
    "model = RandomForestClassifier(n_estimators=10, verbose=2, random_state=random_state, n_jobs=10)\n",
    "\n",
    "# train the model\n",
    "history = model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing\n",
    "The model is tested on 20% of the inital dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7vLpXbKhsV4o",
    "outputId": "c016d21b-d01e-4cd7-85bd-abb17c21f7b8"
   },
   "outputs": [],
   "source": [
    "# score the model between 0.0 and 1.0\n",
    "score = model.score(X_test, Y_test)\n",
    "print(f'score: {score}')\n",
    "# predict delay casuses using the trained model\n",
    "predictions = history.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Displaying the results\n",
    "\n",
    "We checked the preformance of the model by creating a confusion matrix, as well as checking the precision, recall and f1-score of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 697
    },
    "id": "iFk5FD8XpY9T",
    "outputId": "7e8b7810-3eb9-4201-b4d9-b2c9773a46c6"
   },
   "outputs": [],
   "source": [
    "rownames = categories.from_codes(predictions, categories=categories.categories)\n",
    "colnames = categories.from_codes(Y_test, categories=categories.categories)\n",
    "# create confusion matrix from true and predicted labels\n",
    "conf = pd.crosstab(colnames, rownames, margins=True, normalize='index',)\n",
    "# conf = conf.apply(lambda column: column / column.iloc[len(column)-1], axis=1)\n",
    "\n",
    "# drop the margin\n",
    "#conf = conf.drop(columns=['All'])\n",
    "conf = conf.drop(conf.tail(1).index)\n",
    "\n",
    "# show the confusion matrix\n",
    "conf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Key observations**\n",
    "\n",
    "Overall, the model appears to have a significant bias towards predicting no delays, even with oversampling applied. \n",
    "While it performs reasonably well on static causes such as railway condition related delays and constructions, it struggles with the less frequent causes,\n",
    "particularly the \"Delay due to train's technical fault,\" which is the second most frequent cause of delays. This is probably due to the large number of trains.\n",
    "It is likely that the model would benefit from more data for these infrequent causes in order to improve its performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 301
    },
    "id": "7fwsXzWwh5uS",
    "outputId": "48e7a8db-e05d-462c-daae-d7cefa897741"
   },
   "outputs": [],
   "source": [
    "sns.heatmap(conf)\n",
    "plt.ylabel('true label')\n",
    "plt.xlabel('predicted')\n",
    "plt.title('Confusion matrix (normalized)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(colnames, rownames, zero_division=0))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
