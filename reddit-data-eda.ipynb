{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c309102-6a8b-44cc-9070-f8139a274947",
   "metadata": {},
   "source": [
    "## Longer term delay analysis\n",
    "\n",
    "The data used in this analisys ranges from 2021.01.01 to 2022.9.30.\n",
    "All trains and their positions as well as their potential delays are\n",
    "sampled every minute, resulting in ~10GB data. This dataset does not\n",
    "contain the cause of the delays, but is better suited for analysing\n",
    "trends in delays over a \"long\" period of time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135b8e79-0a76-4b11-99b0-72ea2c842567",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "import dask.dataframe as dd\n",
    "import dask.array as da\n",
    "import dask.bag as db\n",
    "import dask\n",
    "#dask.config.set({\"optimization.fuse.active\": True})\n",
    "\n",
    "from custom_loader import Loader\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "import re\n",
    "\n",
    "#import bamboolib\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79661ea0-92a1-48ed-b6e2-0353fcf767c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def immutable_sort(list_to_sort:list) -> list:\n",
    "    res = list_to_sort.copy()\n",
    "    res.sort()\n",
    "    return res\n",
    "\n",
    "def epoch_to_date(day_since_epoch:int) ->  datetime:\n",
    "    return datetime(1970,1,1) + timedelta(days = day_since_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556e8cf7-f724-4aba-b50e-eb4dd429730b",
   "metadata": {},
   "source": [
    "## Setting up the connection\n",
    "\n",
    "The data is stored in Cassandra db, which is well suited to store large amounts of data.\n",
    "This data was scraped by u/gaborath on reddit, who graciously gave us this sample. He has\n",
    "a cool [website](https://mav-stat.info) on the same topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd85974-9707-452d-a26f-f31bb002f533",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('cassandra-credentials.txt','r') as f:\n",
    "    user = f.readline().strip()\n",
    "    pw = f.readline().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2500f973-488d-4774-b24a-a1827817452f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dask_cassandra_loader = Loader()\n",
    "keyspace = 'mav'\n",
    "cluster = ['vm.niif.cloud.bme.hu']\n",
    "\n",
    "dask_cassandra_loader.connect_to_cassandra(cluster,\n",
    "                                           keyspace,\n",
    "                                           username=user,\n",
    "                                           password=pw, port=11352)\n",
    "dask_cassandra_loader.connect_to_local_dask()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d472fe87-7a91-4884-ab9d-25c47dbf5d76",
   "metadata": {},
   "source": [
    "## Distribution of delays\n",
    "\n",
    "The delays are categorized based on from 0 (non inclusive) to 1000 minutes by 5 minute increments.\n",
    "The resulting distribution can be seen below. (only 0 to 250 displayed for clarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f929b341-08a9-4127-a9a7-e309270d5f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = list(range(0,1000,5))\n",
    "delays_binned = None\n",
    "#epoch range: 18628-19296 \n",
    "for i in tqdm(range(18628,19296,5)):\n",
    "    try:\n",
    "        table = dask_cassandra_loader.load_cassandra_table('train_data',\n",
    "                                                 ['elviraid', 'delay',],\n",
    "                                                           [],\n",
    "                                                 #[('epoch', 'equal', [19221])],\n",
    "                                                 [('epoch', [i,i+1,i+2,i+3,i+4])],\n",
    "                                                 force=False)\n",
    "        if table.data is None:\n",
    "            continue\n",
    "        df = table.data.groupby('elviraid').agg({'delay':'mean'}).reset_index()\n",
    "        df = df['delay'].map_partitions(pd.cut, bins)\n",
    "        if delays_binned is None:\n",
    "            tmp = df.compute()\n",
    "            tmp = tmp.groupby(tmp).size()\n",
    "            delays_binned = tmp\n",
    "        else:\n",
    "            tmp = df.compute()\n",
    "            tmp = tmp.groupby(tmp).size()\n",
    "            delays_binned = delays_binned + tmp\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b033788-10f8-4e74-bbd5-f36e5e6b840a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df = pd.DataFrame({'x':delays_binned.index,'y':delays_binned})\n",
    "plot_df['x'] = plot_df['x'].astype(str)\n",
    "plot_df.to_csv('data/delays_binned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682f1033-3619-4805-8b59-6f581bc6e20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df = pd.read_csv('data/delays_binned.csv').head(50)\n",
    "fig = px.histogram(plot_df,x='x', y='y', title  = 'distribution of mean train delays')\n",
    "fig.update_yaxes(type='log', title='count, logarithmic')\n",
    "fig.update_xaxes(title='delay group (minutes)')\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e352ef-3052-47ce-871c-ea9eb468a046",
   "metadata": {},
   "source": [
    "## The mean delays for each route\n",
    "\n",
    "Finding the mean delays for each route is useful for diagnostical reasons.\n",
    "It can help diagnose problems with:\n",
    "\n",
    "- infrastucture\n",
    "- management\n",
    "- failures in collaboration (with other railway companies)\n",
    "\n",
    "We suggest rescheduling the routes that have a high average delay or fixing\n",
    "the underlying problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8bc64b-a976-4869-8350-04f73c74c5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cumul = None\n",
    "for i in tqdm(range(18628,19296,5)):\n",
    "    success = False\n",
    "    while not success:\n",
    "        try:\n",
    "            table = dask_cassandra_loader.load_cassandra_table('train_data',\n",
    "                                                     ['relation', 'delay',],\n",
    "                                                               [],\n",
    "                                                     #[('epoch', 'equal', [19221])],\n",
    "                                                     [('epoch', [i,i+1,i+2,i+3,i+4])],\n",
    "                                                     force=False)\n",
    "            if table.data is None:\n",
    "                continue\n",
    "            df = table.data.groupby('relation').agg({'delay':'mean'})\n",
    "            if cumul is None:\n",
    "                cumul = df.compute().reset_index()\n",
    "                cumul['delay'] = np.where(cumul['delay'].isna(),0,cumul['delay'])\n",
    "            else:\n",
    "                tmp = df.compute().reset_index()\n",
    "                tmp['delay'] = np.where(tmp['delay'].isna(),0,tmp['delay'])\n",
    "                cumul = pd.concat([cumul, tmp]).groupby(by='relation').mean()\n",
    "            success = True\n",
    "        except Exception as e:\n",
    "            print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "648cbc65-37c1-41ca-a626-a37d337dfeaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_delay_route = cumul.reset_index()\n",
    "mean_delay_route['relation'] = mean_delay_route['relation'].apply(lambda x: x.split(' - '))\n",
    "mean_delay_route['relation'] = mean_delay_route['relation'].apply(immutable_sort)\n",
    "mean_delay_route['relation'] = mean_delay_route['relation'].astype(str)\n",
    "mean_delay_route = mean_delay_route.groupby('relation').mean().reset_index()\n",
    "mean_delay_route = mean_delay_route.sort_values(by=['delay'], ascending=[False])\n",
    "mean_delay_route.to_csv('data/mean_delay_route.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d207f390-a13f-4518-ab4b-da979913f9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df = pd.read_csv('data/mean_delay_route.csv').head(10)\n",
    "print(plot_df)\n",
    "fig = px.bar(plot_df, x='relation', y='delay', title='Mean delays for each route (Top 10)')\n",
    "fig.update_yaxes(title = 'mean delay (min)')\n",
    "fig.update_xaxes(title = 'route')\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00673972-6227-4e8d-adf9-86e4d9c827a8",
   "metadata": {},
   "source": [
    "## Observing seasonality in delays\n",
    "\n",
    "By creating a time series based on the mean delays, we might be able to observe\n",
    "seasonility in delays, which can help diagnose the shortcomings of the current\n",
    "system when it comes to weather conditions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a94403-eb65-4421-9d88-c92a2e90708e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cumul = None\n",
    "for i in tqdm(range(18628,19296,5)):\n",
    "    table = dask_cassandra_loader.load_cassandra_table('train_data',\n",
    "                                             ['epoch', 'elviraid', 'delay',],\n",
    "                                                       [],\n",
    "                                             [('epoch', [i,i+1,i+2,i+3,i+4])],\n",
    "                                             force=False)\n",
    "    if table.data is None:\n",
    "        continue\n",
    "    df = table.data.groupby(['epoch','elviraid']).agg({'delay':'mean'})\n",
    "    df['is_delayed'] = df['delay'].map_partitions(lambda x: x > 1)\n",
    "    df = df.reset_index(0)\n",
    "    df = df.groupby(['epoch','is_delayed']).size().compute().reset_index(0).rename(columns={0:'count'})\n",
    "    if cumul is None:\n",
    "        cumul = df\n",
    "    else:\n",
    "        cumul = pd.concat([cumul,df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e7833d-9e10-43ea-94a7-879e88762883",
   "metadata": {},
   "outputs": [],
   "source": [
    "delay_percentage = cumul.reset_index().pivot(index='epoch',columns=['is_delayed'])\n",
    "delay_percentage = delay_percentage['count']\n",
    "delay_percentage.columns = delay_percentage.columns.ravel()\n",
    "delay_percentage = delay_percentage.rename(columns={False:'not_delayed_count',True:'delayed_count'})\n",
    "delay_percentage['delayed_percentage'] = (delay_percentage['delayed_count'] / (delay_percentage['delayed_count']+delay_percentage['not_delayed_count']))*100\n",
    "delay_percentage.to_csv('data/delay_percentage.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f50e0b-f5ca-4c05-ae60-b812c3ebdf20",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df = pd.read_csv('data/delay_percentage.csv')\n",
    "plot_df['epoch'] = plot_df['epoch'].apply(epoch_to_date)\n",
    "plot_df['sma30'] = plot_df['delayed_percentage'].rolling(30).mean()\n",
    "fig = px.line(plot_df, x='epoch', y = ['delayed_percentage','sma30'],\n",
    "              title = 'Percentage of trains with mean delays longer 1 minute')\n",
    "fig.update_yaxes(title = 'percentage of delayed trains')\n",
    "fig.update_xaxes(title = 'date')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76669b8b-2cf8-4006-9cfa-d99ffac63996",
   "metadata": {},
   "source": [
    "## Trains with high average delays\n",
    "\n",
    "Trains with high average delays might be in bad condition, suggesting they need to be\n",
    "serviced or retired entirely. However, high average delays might be caused by factors\n",
    "outside the trains' conditions, which is why we suggest that this data should not be taken\n",
    "out of context and should be examined in conjunction with the routes that have high delays.\n",
    "\n",
    "A short investigation into these trains' conditions could reveal the real causes of the delays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d11426f-e549-49d2-9b13-fae84cd08cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cumul = None\n",
    "#19296\n",
    "for i in tqdm(range(18628,19296,5)):\n",
    "    table = dask_cassandra_loader.load_cassandra_table('train_data',\n",
    "                                             ['trainnumber', 'delay','elviraid'],\n",
    "                                                       [],\n",
    "                                             [('epoch', [i,i+1,i+2,i+3,i+4])],\n",
    "                                             force=False)\n",
    "    if table.data is None:\n",
    "        continue\n",
    "    df = table.data.groupby(['trainnumber','elviraid']).agg({'delay':'mean'})\n",
    "    df = df.reset_index(0).compute()\n",
    "    if cumul is None:\n",
    "        cumul = df\n",
    "    else:\n",
    "        cumul = pd.concat([cumul,df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7da4e1-0342-4691-8d83-1f9df782e463",
   "metadata": {},
   "outputs": [],
   "source": [
    "delays_per_train = cumul.groupby('trainnumber').agg({'elviraid':'count','delay':'mean'})\n",
    "delays_per_train = delays_per_train.sort_values(by=['delay'],ascending=[False])\n",
    "delays_per_train.to_csv('data/delays_per_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b6e89e-67e6-4e91-bb64-a8737fb60cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df = pd.read_csv('data/delays_per_train.csv')\n",
    "plot_df = plot_df[plot_df['elviraid']>10].head(10).reset_index()\n",
    "print(plot_df)\n",
    "fig = px.bar(plot_df, x='trainnumber', y='delay', title='Mean delays for each train')\n",
    "fig.update_yaxes(title = 'mean delay (min)')\n",
    "fig.update_xaxes(title = 'train number')\n",
    "fig"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
