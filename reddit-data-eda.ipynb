{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c309102-6a8b-44cc-9070-f8139a274947",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Longer term delay analysis\n",
    "\n",
    "The data used in this analisys ranges from 2021.01.01 to 2022.09.30.\n",
    "All trains and their positions as well as their potential delays are\n",
    "sampled every minute, resulting in ~10GB data. This dataset does not\n",
    "contain the cause of the delays, but is better suited for analysing\n",
    "trends in delays over a \"long\" period of time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135b8e79-0a76-4b11-99b0-72ea2c842567",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "import dask.dataframe as dd\n",
    "import dask.array as da\n",
    "import dask.bag as db\n",
    "import dask\n",
    "\n",
    "from custom_loader import Loader\n",
    "from tqdm import tqdm\n",
    "\n",
    "import re\n",
    "import os\n",
    "\n",
    "from cassandra.cluster import Cluster\n",
    "from cassandra.auth import PlainTextAuthProvider\n",
    "from cassandra.query import dict_factory\n",
    "\n",
    "import plotly.express as px\n",
    "import holoviews as hv\n",
    "import holoviews.operation.datashader as hd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79661ea0-92a1-48ed-b6e2-0353fcf767c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def immutable_sort(list_to_sort:list) -> list:\n",
    "    res = list_to_sort.copy()\n",
    "    res.sort()\n",
    "    return res\n",
    "\n",
    "def epoch_to_date(day_since_epoch:int) ->  datetime:\n",
    "    return datetime(1970,1,1) + timedelta(days = day_since_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556e8cf7-f724-4aba-b50e-eb4dd429730b",
   "metadata": {},
   "source": [
    "## Setting up the connection\n",
    "\n",
    "The data is stored in Cassandra db, which is well suited to store large amounts of data.\n",
    "This data was scraped by u/gaborath on reddit, who graciously gave us this sample. He has\n",
    "a cool [website](https://mav-stat.info) on the same topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd85974-9707-452d-a26f-f31bb002f533",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('cassandra-credentials.txt','r') as f:\n",
    "    user = f.readline().strip()\n",
    "    pw = f.readline().strip()\n",
    "port=11352"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2500f973-488d-4774-b24a-a1827817452f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dask_cassandra_loader = Loader()\n",
    "keyspace = 'mav'\n",
    "cluster = ['vm.niif.cloud.bme.hu']\n",
    "\n",
    "dask_cassandra_loader.connect_to_cassandra(cluster,\n",
    "                                           keyspace,\n",
    "                                           username=user,\n",
    "                                           password=pw, \n",
    "                                           port=port,\n",
    "                                           timeout=60\n",
    "                                          )\n",
    "dask_cassandra_loader.connect_to_local_dask()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d472fe87-7a91-4884-ab9d-25c47dbf5d76",
   "metadata": {},
   "source": [
    "## Distribution of delays\n",
    "\n",
    "The train journeys are binned by mean delays from 0 (non inclusive) to 1000 minutes by 5 minute increments.\n",
    "The resulting distribution can be seen below. (only 0 to 250 displayed for clarity)\n",
    "The most frequent delays are from 0-5 and 5-10 minutes by a large margin. This is good news, \n",
    "but it is clear that delays that are hour or longer are very frequent. This is probably the reason behind\n",
    "the notoriety of MAV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f929b341-08a9-4127-a9a7-e309270d5f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = list(range(0,1000,5))\n",
    "delays_binned = None\n",
    "#epoch range: 18628-19296 \n",
    "for i in tqdm(range(18628,19296,5)):\n",
    "    try:\n",
    "        table = dask_cassandra_loader.load_cassandra_table('train_data',\n",
    "                                                 ['elviraid', 'delay',],\n",
    "                                                           [],\n",
    "                                                 [('epoch', [i,i+1,i+2,i+3,i+4])],\n",
    "                                                 force=False)\n",
    "        if table.data is None:\n",
    "            continue\n",
    "        df = table.data.groupby('elviraid').agg({'delay':'mean'}).reset_index()\n",
    "        df = df['delay'].map_partitions(pd.cut, bins)\n",
    "        if delays_binned is None:\n",
    "            tmp = df.compute()\n",
    "            tmp = tmp.groupby(tmp).size()\n",
    "            delays_binned = tmp\n",
    "        else:\n",
    "            tmp = df.compute()\n",
    "            tmp = tmp.groupby(tmp).size()\n",
    "            delays_binned = delays_binned + tmp\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b033788-10f8-4e74-bbd5-f36e5e6b840a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df = pd.DataFrame({'x':delays_binned.index,'y':delays_binned})\n",
    "plot_df['x'] = plot_df['x'].astype(str)\n",
    "plot_df.to_csv('data/delays_binned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682f1033-3619-4805-8b59-6f581bc6e20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df = pd.read_csv('data/delays_binned.csv').head(50)\n",
    "fig = px.histogram(plot_df,x='x', y='y', title  = 'distribution of mean train delays')\n",
    "fig.update_yaxes(type='log', title='count, logarithmic')\n",
    "fig.update_xaxes(title='delay group (minutes)')\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e352ef-3052-47ce-871c-ea9eb468a046",
   "metadata": {},
   "source": [
    "## The mean delays for each route\n",
    "\n",
    "Determining the mean delays for each route can be useful for diagnosing various issues, including infrastructure problems, management issues, and failures in collaboration with other railway companies. We recommend rescheduling routes with high average delays or addressing the underlying problems in order to improve efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8bc64b-a976-4869-8350-04f73c74c5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cumul = None\n",
    "to_fetch = 5\n",
    "for i in tqdm(range(18628,19296,to_fetch)):\n",
    "    try:\n",
    "        table = dask_cassandra_loader.load_cassandra_table('train_data',\n",
    "                                                 ['relation', 'delay',],\n",
    "                                                           [],\n",
    "                                                 [('epoch', list(range(i,i+to_fetch)))],\n",
    "                                                 force=False)\n",
    "        if table.data is None:\n",
    "            continue\n",
    "        df = table.data.groupby('relation').agg({'delay':'mean'})\n",
    "        if cumul is None:\n",
    "            cumul = df.compute().reset_index()\n",
    "            cumul['delay'] = np.where(cumul['delay'].isna(),0,cumul['delay'])\n",
    "        else:\n",
    "            tmp = df.compute().reset_index()\n",
    "            tmp['delay'] = np.where(tmp['delay'].isna(),0,tmp['delay'])\n",
    "            cumul = pd.concat([cumul, tmp]).groupby(by='relation').mean()\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "648cbc65-37c1-41ca-a626-a37d337dfeaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_delay_route = cumul.reset_index()\n",
    "mean_delay_route['relation'] = mean_delay_route['relation'].apply(lambda x: x.split(' - '))\n",
    "mean_delay_route['relation'] = mean_delay_route['relation'].apply(immutable_sort)\n",
    "mean_delay_route['relation'] = mean_delay_route['relation'].astype(str)\n",
    "mean_delay_route = mean_delay_route.groupby('relation').mean().reset_index()\n",
    "mean_delay_route = mean_delay_route.sort_values(by=['delay'], ascending=[False])\n",
    "mean_delay_route.to_csv('data/mean_delay_route.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c287a567-ab98-42dc-bc9c-7982736fd624",
   "metadata": {},
   "source": [
    "**It is important to note that the mean delays for routes were analyzed without considering directionality, meaning that a route from A to B was treated the same as a route from B to A.**\n",
    "\n",
    "The top 10 routes with the highest average delays are almost all routes with a destination abroad. This is likely due to these routes being the longest in duration, rather than any issues with collaboration. This is supported by the fact that the destinations abroad are not located in a single country. In addition to this, the Budapest-Keleti to Sopron route, which does not lead abroad, is also in the top 10. However, this route is one of the longest routes in Hungary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d207f390-a13f-4518-ab4b-da979913f9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df = pd.read_csv('data/mean_delay_route.csv', index_col = 0).head(10)\n",
    "print(plot_df)\n",
    "fig = px.bar(plot_df, x='relation', y='delay', title='Mean delays for each route (Top 10)')\n",
    "fig.update_yaxes(title = 'mean delay (min)')\n",
    "fig.update_xaxes(title = 'route')\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00673972-6227-4e8d-adf9-86e4d9c827a8",
   "metadata": {},
   "source": [
    "## Observing seasonality in delays\n",
    "\n",
    "By creating a time series based on the mean delay per journey, we are able to observe\n",
    "seasonility in delays. This can help diagnose the shortcomings of the current\n",
    "system when it comes to weather conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a94403-eb65-4421-9d88-c92a2e90708e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cumul = None\n",
    "for i in tqdm(range(18628,19296,5)):\n",
    "    table = dask_cassandra_loader.load_cassandra_table('train_data',\n",
    "                                             ['epoch', 'elviraid', 'delay',],\n",
    "                                                       [],\n",
    "                                             [('epoch', [i,i+1,i+2,i+3,i+4])],\n",
    "                                             force=False)\n",
    "    if table.data is None:\n",
    "        continue\n",
    "    df = table.data.groupby(['epoch','elviraid']).agg({'delay':'mean'})\n",
    "    df['is_delayed'] = df['delay'].map_partitions(lambda x: x > 1)\n",
    "    df = df.reset_index(0)\n",
    "    df = df.groupby(['epoch','is_delayed']).size().compute().reset_index(0).rename(columns={0:'count'})\n",
    "    if cumul is None:\n",
    "        cumul = df\n",
    "    else:\n",
    "        cumul = pd.concat([cumul,df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e7833d-9e10-43ea-94a7-879e88762883",
   "metadata": {},
   "outputs": [],
   "source": [
    "delay_percentage = cumul.reset_index().pivot(index='epoch',columns=['is_delayed'])\n",
    "delay_percentage = delay_percentage['count']\n",
    "delay_percentage.columns = delay_percentage.columns.ravel()\n",
    "delay_percentage = delay_percentage.rename(columns={False:'not_delayed_count',True:'delayed_count'})\n",
    "delay_percentage['delayed_percentage'] = (delay_percentage['delayed_count'] / (delay_percentage['delayed_count']+delay_percentage['not_delayed_count']))*100\n",
    "delay_percentage.to_csv('data/delay_percentage.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d48c735-e2b0-4398-84d3-fc1e28d6157c",
   "metadata": {},
   "source": [
    "Although MAV only includes delays of 5-6 minutes or more in their statistics on punctual trains, we wanted to examine the metric using a different definition of punctuality, specifically considering delays of one minute or more. As expected, the percentage of punctual trains was significantly higher under this definition. To smooth out any fluctuations in the data, we also calculated the 30-day moving average. While the metric remains somewhat noisy, it is clear that trains are most punctual in the spring, with approximately 70-80% of journeys still being on time. This may be due to the favorable weather conditions during this season."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f50e0b-f5ca-4c05-ae60-b812c3ebdf20",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df = pd.read_csv('data/delay_percentage.csv')\n",
    "plot_df['epoch'] = plot_df['epoch'].apply(epoch_to_date)\n",
    "plot_df['sma30'] = plot_df['delayed_percentage'].rolling(30).mean()\n",
    "fig = px.line(plot_df, x='epoch', y = ['delayed_percentage','sma30'],\n",
    "              title = 'Percentage of journeys with mean delays longer 1 minute')\n",
    "fig.update_yaxes(title = 'percentage of delayed trains')\n",
    "fig.update_xaxes(title = 'date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351c29e7-9f94-435e-90f5-3c5e3ab7b4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "auth_provider = PlainTextAuthProvider(username=user, password=pw)\n",
    "cluster = Cluster(contact_points=['vm.niif.cloud.bme.hu'], port=port,\n",
    "    auth_provider=auth_provider)\n",
    "session = cluster.connect(keyspace)\n",
    "session.row_factory = dict_factory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4738e8-ce93-4261-b2ea-bfefc5a9f67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_epoch = 18628\n",
    "max_epoch = 19296\n",
    "epochs = []\n",
    "daily_mean_delays = []\n",
    "daily_max_delays = []\n",
    "\n",
    "for epoch in tqdm(range(min_epoch,max_epoch)):\n",
    "    success = False\n",
    "    while not success:\n",
    "        try:\n",
    "            sql_query = f\"SELECT epoch, avg(cast(delay as FLOAT)) AS mean, max(delay) as max  FROM train_data WHERE epoch = {epoch} AND delay < 500 GROUP BY epoch ALLOW FILTERING\"\n",
    "            dict = session.execute(sql_query).one()\n",
    "            success = True\n",
    "            if dict is None:\n",
    "                continue\n",
    "            daily_mean_delays.append(dict['mean'])\n",
    "            daily_max_delays.append(dict['max'])\n",
    "            epochs.append(epoch)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            \n",
    "df = pd.DataFrame({'epoch': pd.Series(data=epochs),\n",
    "                   'mean_delay': pd.Series(data=daily_mean_delays),\n",
    "                    'max_delay': pd.Series(data=daily_max_delays)})\n",
    "\n",
    "df.to_csv('data/daily_mean_and_average_delay.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104b6031-c111-46f7-a0b5-a83a5370ca6b",
   "metadata": {},
   "source": [
    "The mean delays per journey also showed a similar pattern. We found this metric to be somewhat noisy as well, so we again calculated the 30-day moving average to better identify trends. From this analysis, we observed elevated mean delays during the summer months. While we are not experts on the subject, it is possible that this may be due to the summer heat, which can cause metal rails and electrical wires to expand and potentially affect the operation of the trains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7ed0dd-dfe6-4e31-a975-ee105c118a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df = pd.read_csv('data/daily_mean_and_average_delay.csv')\n",
    "plot_df['epoch'] = plot_df['epoch'].apply(epoch_to_date)\n",
    "plot_df['sma30'] = plot_df['mean_delay'].rolling(30).mean()\n",
    "\n",
    "fig = px.line(plot_df, x='epoch', y=['mean_delay', 'sma30'], title='Daily mean delay')\n",
    "fig.update_yaxes(title = 'delay (min)')\n",
    "fig.update_xaxes(title = 'date')\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554616cf-d971-42dd-a926-62ea2f94e9e9",
   "metadata": {},
   "source": [
    "To determine the weather conditions that lead to the longest delays, we calculated the maximum delays for each day. As before, we applied the 30-day moving average to smooth out the data. However, even with the use of the moving average, we were unable to discern any trends in the maximum daily delays. This may suggest that the longest delays are not caused by weather-related factors. However, we were able to spot some inconsistencies in our data. Some periods are missing entries. These can be identified by looking for unusually long straight lines between two dates that are \"far\" apart. Most notably from the 27th of Feburary 2022 to the 30th of March 2022. As we mentioned earlier, we received this data from u/gaborauth and we don't know the cause of the missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79088946-3555-473a-9417-98b61bfce75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df = pd.read_csv('data/daily_mean_and_average_delay.csv')\n",
    "plot_df['epoch'] = plot_df['epoch'].apply(epoch_to_date)\n",
    "plot_df['sma30'] = plot_df['max_delay'].rolling(30).mean()\n",
    "\n",
    "fig = px.line(plot_df, x='epoch', y=['max_delay', 'sma30'], title='Daily max delay')\n",
    "fig.update_yaxes(title = 'delay (min)')\n",
    "fig.update_xaxes(title = 'date')\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f4eadc-e5dc-4996-8e45-a5ef7a24720d",
   "metadata": {},
   "source": [
    "As the daily data required a 30 day moving average to be more easily interpreted, we calculated the monthly mean delay in addition to the daily data. The resulting plot confirmed our initial observations of higher delays in the summer months and lower delays in the spring. This indicates that MAV should prioritize preparation for summer weather in order to reduce the average delay per journey."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399836c3-a8c1-4600-a48f-d5782da7efe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df = pd.read_csv('data/daily_mean_and_average_delay.csv').drop(columns=['max_delay'])\n",
    "plot_df['epoch'] = plot_df['epoch'].apply(epoch_to_date)\n",
    "plot_df = plot_df.set_index('epoch')\n",
    "plot_df = plot_df.resample('M').mean().reset_index()\n",
    "plot_df\n",
    "\n",
    "fig = px.line(plot_df, x='epoch', y='mean_delay', title='Monthly mean delay per journey')\n",
    "fig.update_yaxes(title = 'delay (min)')\n",
    "fig.update_xaxes(title = 'date')\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76669b8b-2cf8-4006-9cfa-d99ffac63996",
   "metadata": {},
   "source": [
    "## Trains with high average delays\n",
    "\n",
    "Trains with high average delays might be in bad condition, suggesting they need to be\n",
    "serviced or retired entirely. However, high average delays might be caused by factors\n",
    "outside the trains' conditions, which is why we suggest that this data should not be taken\n",
    "out of context and should be examined in conjunction with the routes that have high delays.\n",
    "\n",
    "A short investigation into these trains' conditions could reveal the real causes of the delays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d11426f-e549-49d2-9b13-fae84cd08cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cumul = None\n",
    "#19296\n",
    "for i in tqdm(range(18628,19296,5)):\n",
    "    table = dask_cassandra_loader.load_cassandra_table('train_data',\n",
    "                                             ['trainnumber', 'delay','elviraid'],\n",
    "                                                       [],\n",
    "                                             [('epoch', [i,i+1,i+2,i+3,i+4])],\n",
    "                                             force=False)\n",
    "    if table.data is None:\n",
    "        continue\n",
    "    df = table.data.groupby(['trainnumber','elviraid']).agg({'delay':'mean'})\n",
    "    df = df.reset_index(0).compute()\n",
    "    if cumul is None:\n",
    "        cumul = df\n",
    "    else:\n",
    "        cumul = pd.concat([cumul,df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7da4e1-0342-4691-8d83-1f9df782e463",
   "metadata": {},
   "outputs": [],
   "source": [
    "delays_per_train = cumul.groupby('trainnumber').agg({'elviraid':'count','delay':'mean'})\n",
    "delays_per_train = delays_per_train.sort_values(by=['delay'],ascending=[False])\n",
    "delays_per_train.to_csv('data/delays_per_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b6e89e-67e6-4e91-bb64-a8737fb60cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df = pd.read_csv('data/delays_per_train.csv')\n",
    "plot_df = plot_df[plot_df['elviraid']>10].head(10).reset_index()\n",
    "print(plot_df)\n",
    "fig = px.bar(plot_df, x='trainnumber', y='delay', title='Mean delays for each train')\n",
    "fig.update_yaxes(title = 'mean delay (min)')\n",
    "fig.update_xaxes(title = 'train number')\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387bfc27-0552-4f2c-82d1-b0ac7c7cd5c5",
   "metadata": {},
   "source": [
    "## Delay map\n",
    "\n",
    "By analyzing the locations with the highest mean delays, we identified potential railway tracks that may require servicing. This information was obtained by collecting the trains' locations along with the delay data, over an extended period of time by u/gaborauth. However, it is worth noting that the cause of the delays was not recorded, so it is possible that some locations may have high average delays due to factors such as faulty trains or other external factors. Therefore, we recommend that MAV conduct their own internal analysis of track conditions in order to address the delays at these locations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f567ba3b-5aae-45f7-b330-c86b2828a282",
   "metadata": {},
   "outputs": [],
   "source": [
    "cumul = None\n",
    "#19296\n",
    "for i in tqdm(range(18628,19296,5)):\n",
    "    try:\n",
    "        table = dask_cassandra_loader.load_cassandra_table('train_data',\n",
    "                                                 ['lat', 'delay','lon'],\n",
    "                                                           [],\n",
    "                                                 [('epoch', [i,i+1,i+2,i+3,i+4])],\n",
    "                                                 force=False)\n",
    "        if table.data is None:\n",
    "            continue\n",
    "        df = table.data[table.data['delay']<500]\n",
    "        if cumul is None:\n",
    "            cumul = df\n",
    "        else:\n",
    "            cumul = dd.concat([cumul,df]).compute()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "cumul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9960eb9d-b4d4-4105-9968-bfdcea8033e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datashader as ds, colorcet\n",
    "from bokeh.plotting import figure, show\n",
    "from bokeh.models import LinearColorMapper, BasicTicker, ColorBar\n",
    "import datashader.transfer_functions as tf\n",
    "%opts Image [colorbar=True](cmap=colorcet.fire)\n",
    "hv.extension(\"bokeh\", \n",
    "             #'matplotlib'\n",
    "            ) \n",
    "shaded = hd.datashade(hv.Points(cumul, ['lon', 'lat']), cmap=colorcet.fire, aggregator=ds.mean('delay'))\n",
    "dmap = hd.dynspread(shaded, threshold=0.5, max_px=4).opts(bgcolor='black', xaxis=None, yaxis=None, width=1000, height=600)\n",
    "dmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205cba12-1d73-468d-9b7d-9b5bfbf299d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "\n",
    "fig = plt.figure(figsize=(9, 9))\n",
    "\n",
    "grid = ImageGrid(fig, 111, nrows_ncols=(1, 1), axes_pad=0.5, share_all=False,\n",
    "                 cbar_location=\"right\", cbar_mode=\"each\", cbar_pad=\"2%\")\n",
    "\n",
    "artist0 = dsshow(cumul, ds.Point('lon', 'lat'), ds.mean('delay'),norm='eq_hist', ax=grid[0])\n",
    "\n",
    "cbar = plt.colorbar(artist0, cax=grid.cbar_axes[0], extend='both')\n",
    "cbar.minorticks_on()\n",
    "grid[0].set_title('Train locations color-coded by average delay (minutes)')\n",
    "plt.savefig('plots/delay-color-coded1.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eca19d7-b84f-4ca5-90f7-6e5f8d9b7df1",
   "metadata": {},
   "source": [
    "Unfortunately, we were unable to include a colorbar in the first map. The map displays the average delay at each location, with brighter colors indicating higher average delays. It is worth noting that some locations with very high average delays appear outside of the track limits, which is due to inaccurate location reporting. To improve visualization, histogram equalization was applied to the data, which may distort the perception of track condition severity as smaller values appear closer to larger values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b945751-1bed-4dde-90fe-9bfca1655ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "img = mpimg.imread('plots/delay-color-coded.png')\n",
    "f = plt.figure()\n",
    "f.set_figwidth(20)\n",
    "f.set_figheight(12)\n",
    "imgplot = plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d19434b0-fe25-4a21-b15b-c18f0bb6b40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "img = mpimg.imread('plots/delay-color-coded-mpl.png')\n",
    "f = plt.figure()\n",
    "f.set_figwidth(20)\n",
    "f.set_figheight(12)\n",
    "imgplot = plt.imshow(img)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
